---
title: "3 layers autoencoder model - ANN2 library"
output: html_notebook
---

```{r}
#clear environment
rm(list=ls())
gc()
```
ANN2 is a library used to congure autoencoder. Using ANN2 it is possible to conduct a
training of general classification and regression neural networks using gradient descent. ANN2 contains Special features include a function for training replicator neural networks and a function for training autoencoders. Multiple activation and cost functions (including Huber and pseudo-Huber) are supported, as well as L1 and L2 regularization, momentum, early stopping and the possibility to specify a learning rate schedule. The package contains a vectorized gradient descent implementation which facilitates faster training through batch learning.
```{r}
#NN and autoencoder library
install.packages("ANN2")
library(ANN2)

#general
batchSize <- 256
learningRate <-  1e-06
momentum <- 0.1
maxEpochs <- 100
lossFunction <- "huber"
if(lossFunction == "huber" | lossFunction == "pseudo-huber"){
  huberCutOff <- 3
}
L2Regularization <- 1e-3



#The first hidden layer config
firstLayerUnits <- 30

#The first hidden layer config
SecodnLayerUnits <- 15

#The first hidden layer config
ThirdLayerUnits <- firstLayerUnits
```


Creating autoencoder model using autoencoder() function from ANN2 library.
```{r}
if(huberCutOff){
  autoencoder <- autoencoder(
                        X = x_train, 
                        hiddenLayers = c(firstLayerUnits, SecodnLayerUnits, ThirdLayerUnits),
                        lossFunction = lossFunction,
                        dHuber = huberCutOff,
                        maxEpochs = maxEpochs,
                        standardize = FALSE,
                        learnRate = learningRate,
                        batchSize = batchSize,
                        momentum = momentum,
                        L2 = L2Regularization,
                        validLoss = TRUE,
                        verbose = TRUE,
                        robErrorCov = TRUE
                        )
}else{
    autoencoder <- autoencoder(
                        X = x_train, 
                        hiddenLayers = c(firstLayerUnits, SecodnLayerUnits, ThirdLayerUnits),
                        lossFunction = lossFunction,
                        maxEpochs = maxEpochs,
                        standardize = FALSE,
                        learnRate = learningRate,
                        batchSize = batchSize,
                        momentum = momentum,
                        L2 = L2Regularization,
                        validLoss = TRUE,
                        verbose = TRUE,
                        robErrorCov = TRUE
                        )
}
```

```{r}
plot(autoencoder)
rX <- reconstruct(autoencoder, x_train)
#difference between x_train and rX gives us anomalies in x_train dataset.
```